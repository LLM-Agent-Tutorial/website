<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Foundations · LLM Agent Tutorial</title>
  <link rel="stylesheet" href="styles.css" />
  <script defer src="script.js"></script>
</head>
<body data-page="foundations" data-nav="foundations">
  <header class="site-header">
    <div class="inner">
      <div class="logo">LLM Agent Tutorial</div>
      <button class="nav-toggle" aria-controls="mainNav" aria-expanded="false">Menu</button>
      <nav class="primary-nav" id="mainNav">
        <a href="index.html" data-nav-target="home">Home</a>
        <a href="foundations.html" data-nav-target="foundations">Foundations</a>
        <a href="capabilities.html" data-nav-target="capabilities">Agent Examples</a>
        <a href="practical-tips.html" data-nav-target="practical">Practical Tips</a>
        <a href="advanced-techniques.html" data-nav-target="advanced">Advanced Frontier</a>
      </nav>
      <a class="download-btn" href="LLM_Agent_Tutorial%20(3).pdf" download>Download <span>PDF</span></a>
    </div>
  </header>

  <div class="layout">
    <aside class="chapter-sidebar">      <ul class="chapter-links">
        <li><a data-chapter-link="home" href="index.html">Homepage &amp; Abstract</a></li>
        <li><a data-chapter-link="foundations" href="foundations.html">What you must know about LLM Agents</a></li>
        <li>
          <span>What LLM agents can do and how they work</span>
          <ul class="sub-chapter-links">
            <li><a data-chapter-link="capabilities" href="capabilities.html">Chapter overview</a></li>
            <li><a data-chapter-link="generative-agents" href="generative-agents.html">Generative Agents</a></li>
            <li><a data-chapter-link="ai-scientist" href="ai-scientist.html">The AI Scientist</a></li>
            <li><a data-chapter-link="cellagent" href="cellagent.html">CellAgent</a></li>
            <li><a data-chapter-link="virtual-lab" href="virtual-lab.html">The Virtual Lab</a></li>
            <li><a data-chapter-link="metagpt" href="metagpt.html">MetaGPT</a></li>
            <li><a data-chapter-link="finagent" href="finagent.html">FinAgent</a></li>
            <li><a data-chapter-link="voyager" href="voyager.html">Voyager</a></li>
            <li><a data-chapter-link="mobile-agent" href="mobile-agent.html">Mobile Agent</a></li>
            <li><a data-chapter-link="palm-saycan" href="palm-saycan.html">PaLM-SayCan</a></li>
          </ul>
        </li>
        <li><a data-chapter-link="practical" href="practical-tips.html">Practical Tips</a></li>
        <li><a data-chapter-link="advanced" href="advanced-techniques.html">Advanced Techniques</a></li>
      </ul>
    </aside>

    <main>
      <section id="llm-basics" class="content-section">
        <p class="section-label">Preliminaries</p>
        <h1 class="section-title">Large language models at a glance</h1>
        <p>
          Large language models (LLMs), such as the GPT, DeepSeek, Gemini, and Claude families, are deep learning models
          with billions of parameters, pre-trained on vast amounts of data. This data, typically sourced from
          human-generated content, includes web pages, codebases, textbooks, and more. Through exposure to these corpora,
          LLMs develop the ability to understand and generate language.
        </p>
        <p>
          Because their interface is plain text, people can instruct LLMs to generate code, solve math problems, answer
          healthcare questions, translate, or craft poetry &mdash; as long as both instructions and outputs can be expressed
          as text. A clear prompt that sets context and desired behavior usually leads to usable responses.
        </p>
      </section>

      <section id="next-token" class="content-section">
        <p class="section-label">Core operation</p>
        <h2 class="section-title">Next-token prediction and context windows</h2>
        <p>
          The fundamental operation behind LLMs is next-token prediction. Let <em>x</em> denote the textual input to the model
          (the prompt). Given <em>x</em>, an LLM generates output by predicting one token at a time, ultimately producing a
          sequence of tokens <em>y</em> = (y<sub>1</sub>, &hellip;, y<sub>T</sub>). Formally, this can be represented as
          p(y | x) = &prod;<sub>t=1..T</sub> p(y<sub>t</sub> | x, y<sub>1..t-1</sub>).
        </p>
        <p>
          When predicting the next token, both the prompt and the generated tokens live inside a finite context window,
          which caps the maximum length of text the model can reason over at once. Managing that window &mdash; via careful
          prompting or memory mechanisms &mdash; becomes essential once agents need to operate over extended workflows.
        </p>
      </section>

      <section id="llm-vs-agent" class="content-section">
        <p class="section-label">From models to agents</p>
        <h2 class="section-title">What makes an LLM agent?</h2>
        <p>
          There is no universally accepted definition of an AI agent, so the line between an LLM and an LLM agent can
          blur. In contrast to a single prompt-response interaction, LLM agents usually manage multi-stage tasks that
          unfold through structured workflows instead of one-shot model calls. They often pair the base model with memory,
          planning, role-play, tool use, cooperation, and reflection modules so the system can sustain longer goals.
        </p>
        <p>
          The table of examples in Section&nbsp;3 shows how these abilities manifest in practice. Most agents display at
          least some of them, distinguishing the agentic scaffolding from native LLM behavior.
        </p>
      </section>

      <section id="capabilities" class="content-section">
        <p class="section-label">Key capabilities</p>
        <h2 class="section-title">Six building blocks highlighted in the tutorial</h2>
        <p class="section-intro">
          Below are the capability summaries quoted directly from Section&nbsp;2. Use them as a checklist when designing
          your own agent scaffolds.
        </p>
        <div class="card-grid">
          <article class="info-card">
            <h3>Memory</h3>
            <p>Memory is an agent's capacity to store, recall, and leverage information from prior interactions. Because
              LLMs have finite context windows, agents selectively retain, merge, and reflect on past information.</p>
          </article>
          <article class="info-card">
            <h3>Role-play</h3>
            <p>Role-play denotes an agent's ability to take descriptions such as demographic information or professional
              roles as input and generate behaviors that reflect those attributes across conversations and decisions.</p>
          </article>
          <article class="info-card">
            <h3>Planning</h3>
            <p>Planning decomposes complex goals into coherent sub-tasks. Agents refine each step, reflect on progress,
              and adapt when interfaces or conditions change.</p>
          </article>
          <article class="info-card">
            <h3>Tool use</h3>
            <p>Tool use refers to selecting, composing, and invoking external functions, environments, or APIs. Generated
              code and structured function calls execute outside the model and flow back as verified observations.</p>
          </article>
          <article class="info-card">
            <h3>Cooperation</h3>
            <p>Cooperation lets agents coordinate with humans or other agents by sharing goals, dividing labor, aligning
              strategies, and maintaining trust even under conflicting incentives.</p>
          </article>
          <article class="info-card">
            <h3>Reflection</h3>
            <p>Reflection mirrors the human ability to reconsider past behavior. Agents critique performance, summarize
              lessons, and revise future actions, improving robustness in complex environments.</p>
          </article>
        </div>
      </section>

      <div class="page-nav">
        <a class="page-nav-btn" href="index.html">Back to Home</a>
        <a class="page-nav-btn primary" href="capabilities.html">Next</a>
      </div>
    </main>

    <aside class="progress-sidebar">
      <h2>On this page</h2>
      <ul class="progress-list">
        <li><a class="progress-link" data-target="llm-basics" href="#llm-basics">LLM basics</a></li>
        <li><a class="progress-link" data-target="next-token" href="#next-token">Next-token prediction</a></li>
        <li><a class="progress-link" data-target="llm-vs-agent" href="#llm-vs-agent">From LLM to agent</a></li>
        <li><a class="progress-link" data-target="capabilities" href="#capabilities">Capabilities</a></li>
      </ul>
      <div class="progress-meter"><div class="progress-meter-fill"></div></div>
    </aside>
  </div>

  <footer class="footer">© 2025 Hu et al. · Section 2 companion summary.</footer>
</body>
</html>
