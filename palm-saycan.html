<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>PaLM-SayCan Â· LLM Agent Tutorial</title>
  <link href="libs/bootstrap/bootstrap.min.css" rel="stylesheet" />
  <link rel="stylesheet" href="styles.css" />
  <script defer src="libs/bootstrap/bootstrap.bundle.min.js"></script>
  <script defer src="script.js"></script>
  <script defer id="mathjax" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</head>
<body data-page="palm-saycan" data-nav="capabilities">
    <header class="site-header navbar navbar-expand-lg navbar-light bg-white">
    <div class="inner container-xxl">
      <a class="navbar-brand logo" href="index.html">LLM Agent Tutorial</a>
      <button class="navbar-toggler nav-toggle" type="button" data-bs-toggle="collapse" data-bs-target="#mainNav" aria-controls="mainNav" aria-expanded="false" aria-label="Toggle navigation">
        <span class="navbar-toggler-icon"></span>
      </button>
      <nav class="collapse navbar-collapse primary-nav" id="mainNav">
        <div class="navbar-nav ms-auto align-items-lg-center gap-2">
          <a class="nav-link" href="index.html" data-nav-target="home">Home</a>
          <a class="nav-link" href="foundations.html" data-nav-target="foundations">Foundations</a>
          <a class="nav-link" href="capabilities.html" data-nav-target="capabilities">Agent Examples</a>
          <a class="nav-link" href="practical-tips.html" data-nav-target="practical">Practical Tips</a>
          <a class="nav-link" href="advanced-knowledge.html" data-nav-target="advanced">Advanced Frontier</a>
          <a class="download-btn nav-download-btn d-lg-none text-center mt-2 mx-auto" href="A Beginner-Friendly Tutorial on LLM-based Agents.pdf" download>Download <span>PDF</span></a>
        </div>
      </nav>
      <a class="download-btn ms-lg-3 d-none d-lg-inline-flex" href="A Beginner-Friendly Tutorial on LLM-based Agents.pdf" download>Download <span>PDF</span></a>
    </div>
  </header>

  <div class="layout container-xxl">
    <div class="row g-4 flex-xl-nowrap">
        <aside class="chapter-sidebar col-12 col-xl-3 col-xxl-3 order-2 order-xl-1">
  <ul class="chapter-links">
    <li><a data-chapter-link="home" href="index.html">Homepage</a></li>
    <li><a data-chapter-link="foundations" href="foundations.html">What You Must Know About LLM Agents</a></li>
    <li><a data-chapter-link="capabilities" href="capabilities.html">What LLM Agents Can Do and How They Work</a></li>
    <li>
      <span class="chapter-parent">Example</span>
      <ul class="sub-chapter-links">
        <li><a data-chapter-link="generative-agents" href="generative-agents.html">Generative Agents</a></li>
        <li><a data-chapter-link="ai-scientist" href="ai-scientist.html">The AI Scientist</a></li>
        <li><a data-chapter-link="cellagent" href="cellagent.html">CellAgent</a></li>
        <li><a data-chapter-link="virtual-lab" href="virtual-lab.html">The Virtual Lab</a></li>
        <li><a data-chapter-link="metagpt" href="metagpt.html">MetaGPT</a></li>
        <li><a data-chapter-link="finagent" href="finagent.html">FinAgent</a></li>
        <li><a data-chapter-link="voyager" href="voyager.html">Voyager</a></li>
        <li><a data-chapter-link="mobile-agent" href="mobile-agent.html">Mobile Agent</a></li>
        <li><a data-chapter-link="palm-saycan" href="palm-saycan.html">PaLM-SayCan</a></li>
      </ul>
    </li>
    <li><a data-chapter-link="practical" href="practical-tips.html">Practical Tips</a></li>
    <li>
      <span class="chapter-parent">Advanced Techniques: What is happening at the frontier</span>
      <ul class="sub-chapter-links">
        <li><a data-chapter-link="adv-knowledge" href="advanced-knowledge.html">Injecting Domain Knowledge</a></li>
        <li><a data-chapter-link="adv-reasoning" href="advanced-reasoning.html">Enhancing Reasoning Capabilities</a></li>
        <li><a data-chapter-link="adv-context" href="advanced-context.html">Managing Long Context</a></li>
        <li><a data-chapter-link="adv-internalize" href="advanced-internalize.html">Internalizing Agent Abilities</a></li>
        <li><a data-chapter-link="adv-safety" href="advanced-safety.html">Agent Safety</a></li>
      </ul>
    </li>
  </ul>
</aside>


    <main class="col-12 col-xl-6 col-xxl-6 order-1 order-xl-2 main-content">
      <section id="saycan-overview" class="content-section">
        <h1 class="section-title">PaLM-SayCan: A Clear, Grounded Agent Pattern</h1>
        <div class="resource-links">
          <a class="resource-link" href="https://arxiv.org/pdf/2204.01691" target="_blank" rel="noreferrer">Paper &nearr;</a>
          <a class="resource-link" href="https://say-can.github.io/" target="_blank" rel="noreferrer">Website &nearr;</a>
        </div>
        <div class="overview-highlight">
          <p>
            Embodied agents must turn open-ended language into safe, effective behavior amid partial observability, long horizons, hardware limits, and real-time uncertainty. Typical failures include vague plans that ignore geometry, hallucinated capabilities the robot does not have, and unsafe actions a robot cannot execute. PaLM-SayCan addresses these issues by separating high-level reasoning from low-level feasibility. At each step it asks: <i>What is useful to do next</i>? (Say) and <i>What can the robot actually do now?</i> (Can). Only actions that are both useful and feasible are executed. At decision time, the agent takes the user's instruction, its current state, and a library of named skills. The LLM ranks the skills by how helpful each one would be right now (<i>Say</i>). A pre-trained affordance model then estimates how likely each skill is to succeed in the current scene (<i>Can</i>). The system combines usefulness and feasibility, executes the top skill, logs the outcome, updates state, and repeats until the goal is reached or no safe, feasible action remains.
          </p>
        </div>
        <figure class="hero-figure">
          <img src="imgs/palm-saycan.png" alt="PaLM-SayCan combining Say and Can scores" />
          <figcaption>LLMs have not interacted with their environment and observed the outcome of their responses, and thus are not grounded in the world. SayCan grounds LLMs via value functions of pretrained skills, allowing them to execute real-world, abstract, long-horizon commands on robots.</figcaption>
        </figure>
        <p>We will now use examples and prompt templates to illustrate how PaLM-SayCan integrates <strong>planning</strong>, <strong>Tool use</strong>, and <strong>reflection</strong> to produce safe, feasible robot behavior.</p>
      </section>

      <section id="saycan-planning" class="content-section">
        <h2 class="section-title">Planning (Say)</h2>
        <p>
          The LLM acts as a <i>semantic planner over a fixed skill set</i>. It does not invent new primitives; it scores which provided skill is most useful now, optionally revealing short reasoning for interpretability.
        </p>
        <div class="detail-box detail-box--has-divider">
          <div class="detail-box__header">
            <h4>Example of planning (Say)</h4>
          </div>
          <div class="detail-box__body">
            <p><strong>INPUT:</strong><p> 
            <p><strong>Role</strong>: Semantic planner for a mobile manipulator. Select the most useful next skill from a list. <br>
              <ul>
                <li><i>Instruction</i>: e.g., "I spilled my drink." </li>
                <li><i>Available Skills</i>: e.g., <code>["find a sponge", "pick up sponge", "find an apple"]</code></li>
                <li><i>Task Progress</i>:e.g., "No cleanup tools found yet."</li>
              </ul>
              <strong>Constraints</strong>: Score every listed skill with a probability (scores sum to 1). Use concise, commonsense reasoning. Do not propose skills outside the list.</p>
            <hr class="detail-divider" />
            <p><strong>OUTPUT:</strong></p> 
            <strong>Utility scores</strong>: -find sponge: 0.85; pick up sponge: 0.10; find apple: 0.05.<br> 
            <strong>Rationale</strong>: Locate a cleaning tool before manipulation; ignore irrelevant goals.</p>
          </div>
        </div>
      </section>

      <section id="saycan-tools" class="content-section">
        <h2 class="section-title">Tool use</h2>
        <p>
          SayCan treats low-level abilities as tools that must be grounded in two ways. First, <strong>text-to-skill grounding</strong>: each skill exposes a human-readable name and description (and optional arguments) so the LLM can align language to capabilities. Second, <strong>execution grounding</strong>: each skill has an executor with preconditions and postconditions; execution returns a structured outcome (success/failure and observations) that updates the progress log and the robot's state. Adding capabilities is modular: register a new skill by its name/description, provide (or train) its executor and an affordance estimator, and it immediately becomes available to the planner.
        </p>
        <div class="detail-box detail-box--has-divider">
          <div class="detail-box__header">
            <h4>Example of skill schema</h4>
          </div>
          <div class="detail-box__body">
            <p><strong>Name</strong>: <code>open_refrigerator</code> <br>
            <strong>Description</strong>: Open the refrigerator door using the handle. <br>
            <strong>Preconditions</strong>: handle visible and within reach; gripper free <br>
            <strong>Postconditions</strong>: door angle &gt; 20&deg; <br>
            <strong>Executor</strong> : grasp&rightarrow;pull&rightarrow;release <br>
            <strong>Affordance</strong>: \(A_{\text{open_refrigerator}}(x)\) predicts success from detections, depth, reachability.</p>
          </div>
        </div>
      </section>

      <section id="saycan-reflection" class="content-section">
        <h2 class="section-title">Reflection (Can)</h2>
        <p>
          Reflection is the feasibility check that keeps the plan honest. For each available skill, a pre-trained affordance function (learned from robot experience) estimates the likelihood of success in the current scene. Unlike the "Say" step, the "Can" step is not generated by an LLM. Instead, it is computed by a pre-trained affordance model. In the original SayCan implementation, this model is a languageconditioned value function. This value function is trained on a large dataset of real-world robot rollouts from task execution. Its specific function is to take the robot's current observation state and a natural language description of a skill (e.g., "pick up the apple") as input. It then outputs a scalar score that predicts the expected probability of successfully executing that skill. In the final decision-making phase, the system integrates the outputs from both modules: "Say" (LLM) provides the linguistic usefulness probability for each skill, and "Can" (Affordance Model) provides the physical feasibility probability for each skill. The system multiplies these two scores to obtain a final score for each skill, ultimately selecting the skill with the highest score for execution.
        </p>
        <div class="detail-box detail-box--has-divider">
          <div class="detail-box__header">
            <h4>Example of reflection (Can) and decision</h4>
          </div>
          <div class="detail-box__body">
            <p><strong>INPUT:</strong></p> 
            <p><strong>Instruction</strong>: I'd like a cold apple. <br>
            <p><strong>Scene</strong>: The robot is far from a closed refrigerator; the handle is visible but out of reach.<br>
            <p><strong>Skills</strong>: [1] navigate to refrigerator, [2] open refrigerator, [3] pick up apple.<br>
            <p><strong>Planning (Say) utilities</strong>: navigate: 0.50; open: 0.40; pick up: 0.10. <br>
            <p><strong>Affordance (Can) estimates</strong>: navigate: 0.95 (clear path); open: 0.20 (too far); pick up: 0.05 (not visible).</p>
            <hr class="detail-divider" />
            <p><strong>OUTPUT:</strong> Combined scores favor <i>navigate to refrigerator</i>. After moving, the affordance for <i>open refrigerator</i> rises, so the next step becomes opening the door, followed by picking up the apple.</p>
          </div>
        </div>
      </section>

      <p class="citation-intro">If you find this work helpful, please consider citing our paper:</p>
      <section class="citation-block">
        
        <pre><code>@article{hu2025llm_agents_tutorial,
  title={A Beginner-Friendly Tutorial on LLM-based Agents},
  author={Hu, Shuyue and Ren, Siyue and Chen, Yang and Mu, Chunjiang and Liu, Jinyi and Cui, Zhiyao and Zhang, Yiqun and Li, Hao and Zhou, Dongzhan and Xu, Jia and Zhang, Qiaosheng and Han, Chu and Zheng, Yan and Hao, Jianye and Wang, Zhen},
  year={2025},
  month={November},
  note={Manuscript in preparation}
}</code></pre>
      </section>
      <div class="page-nav">
        <a class="page-nav-btn" href="index.html">Back to Home</a>
        <a class="page-nav-btn primary" href="practical-tips.html">Next</a>
      </div>
    </main>

    <aside class="progress-sidebar col-12 col-xl-3 col-xxl-3 order-3 order-xl-3">
      <h2>On this page</h2>
      <ul class="progress-list">
        <li><a class="progress-link" data-target="saycan-overview" href="#saycan-overview">Overview</a></li>
        <li><a class="progress-link" data-target="saycan-planning" href="#saycan-planning">Planning (Say)</a></li>
        <li><a class="progress-link" data-target="saycan-tools" href="#saycan-tools">Tool use</a></li>
        <li><a class="progress-link" data-target="saycan-reflection" href="#saycan-reflection">Reflection (Can)</a></li>
      </ul>
      <div class="progress-meter"><div class="progress-meter-fill"></div></div>
    </aside>
    </div>
  </div>

  <footer class="footer"> hushuyue@pjlab.org.cn</footer>
</body>
</html>
