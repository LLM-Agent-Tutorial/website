<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Injecting Domain Knowledge · LLM Agent Tutorial</title>
  <link rel="stylesheet" href="styles.css" />
  <script defer src="script.js"></script>
  <script defer id="mathjax" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</head>

<body data-page="adv-knowledge" data-nav="advanced">
  <header class="site-header">
    <div class="inner">
      <a class="logo" href="index.html">LLM Agent Tutorial</a>
      <button class="nav-toggle" aria-controls="mainNav" aria-expanded="false">Menu</button>
      <nav class="primary-nav" id="mainNav">
        <a href="index.html" data-nav-target="home">Home</a>
        <a href="foundations.html" data-nav-target="foundations">Foundations</a>
        <a href="capabilities.html" data-nav-target="capabilities">Agent Examples</a>
        <a href="practical-tips.html" data-nav-target="practical">Practical Tips</a>
        <a href="advanced-techniques.html" data-nav-target="advanced">Advanced Frontier</a>
      </nav>
      <a class="download-btn" href="LLM_Agent_Tutorial%20(3).pdf" download>Download <span>PDF</span></a>
    </div>
  </header>

  <div class="layout">

    <aside class="chapter-sidebar">
      <ul class="chapter-links">
        <li><a data-chapter-link="home" href="index.html">Homepage</a></li>
        <li><a data-chapter-link="foundations" href="foundations.html">What You Must Know About LLM Agents</a></li>
        <li><a data-chapter-link="capabilities" href="capabilities.html">What LLM Agents Can Do and How They Work</a>
        </li>
        <li>
          <span class="chapter-parent">Example</span>
          <ul class="sub-chapter-links">
            <li><a data-chapter-link="generative-agents" href="generative-agents.html">Generative Agents</a></li>
            <li><a data-chapter-link="ai-scientist" href="ai-scientist.html">The AI Scientist</a></li>
            <li><a data-chapter-link="cellagent" href="cellagent.html">CellAgent</a></li>
            <li><a data-chapter-link="virtual-lab" href="virtual-lab.html">The Virtual Lab</a></li>
            <li><a data-chapter-link="metagpt" href="metagpt.html">MetaGPT</a></li>
            <li><a data-chapter-link="finagent" href="finagent.html">FinAgent</a></li>
            <li><a data-chapter-link="voyager" href="voyager.html">Voyager</a></li>
            <li><a data-chapter-link="mobile-agent" href="mobile-agent.html">Mobile Agent</a></li>
            <li><a data-chapter-link="palm-saycan" href="palm-saycan.html">PaLM-SayCan</a></li>
          </ul>
        </li>
        <li><a data-chapter-link="practical" href="practical-tips.html">Practical Tips</a></li>
        <li>
          <span class="chapter-parent">Advanced Techniques: What is happening at the frontier</span>
          <ul class="sub-chapter-links">
            <li><a data-chapter-link="adv-knowledge" href="advanced-knowledge.html">Injecting Domain Knowledge</a></li>
            <li><a data-chapter-link="adv-reasoning" href="advanced-reasoning.html">Enhancing Reasoning Capabilities</a>
            </li>
            <li><a data-chapter-link="adv-context" href="advanced-context.html">Managing Long Context</a></li>
            <li><a data-chapter-link="adv-internalize" href="advanced-internalize.html">Internalizing Agent
                Abilities</a></li>
            <li><a data-chapter-link="adv-safety" href="advanced-safety.html">Agent Safety</a></li>
          </ul>
        </li>
      </ul>
    </aside>

    <main>
      <section id="topic-overview" class="content-section">
        <h1 class="section-title">Injecting Domain Knowledge</h1>
        <p>
          Injecting domain knowledge is a critical step to steer a general-purpose LLM into a powerful, expertlevel
          agent. The method chosen for this task depends on the scale of the knowledge, how frequently it changes, and
          the desired behavior of the agent. There are three primary techniques: In-Context Learning,
          Retrieval-Augmented Generation (RAG), and Fine-Tuning.
        </p>
      </section>

      <section id="in-context-learning" class="content-section">
        <h2 class="section-title">In-Context Learning</h2>
        <p>
          The most straightforward way to inject domain knowledge is to place the relevant information directly within
          the LLM's context window. This method leverages the model’s incontext learning ability, allowing it to use the
          provided text as a direct source of truth for generating a response. As the user can dynamically insert any
          piece of information on the fly without requiring any additional infrastructure, in-context learning is very
          agile and is especially effective when the knowledge is limited in scope, such as some trading rules for the
          stock market or the clinical summary for a patient. Below we provide an example of a medical care scenario.
        </p>
        <div class="detail-box detail-box--has-divider">
          <div class="detail-box__header">
            <h4>Example of Injecting Domain Knowledge through In-Context Learning</h4>
          </div>
          <div class="detail-box__body">
            <p><strong>Task</strong>:&nbsp;Triage a patient's chief complaint to recommend an appropriate care setting.
            </p>
            <p><strong>Prompt</strong>:&nbsp;You are an experienced triage nurse. Use the following medical knowledge:
              chest pain with exertional onset, radiating to the jaw/arm, and associated with diaphoresis (sweating) is
              a classic presentation of cardiac ischemia and is an emergency requiring immediate ER evaluation.
              Non-radiating, pleuritic pain (sharp, worse on inspiration) is more suggestive of musculoskeletal or
              pulmonary issues like costochondritis or pneumonia, which may be handled by urgent care. Now triage this
              complaint: "I have a crushing feeling in my chest that started after I mowed the lawn, and I'm sweating
              but feel cold."
            <p><strong>Output</strong>:&nbsp;This is a high-risk presentation. The exertional onset (mowing the lawn),
              crushing quality, and associated diaphoresis (sweating) are hallmark red flags for acute coronary syndrome
              (e.g., a heart attack). This patient requires immediate emergency room evaluation. Do not delay.
            </p>
          </div>
        </div>
        <p>However, this method is not well-suited for extensive knowledge bases. Directly including large volumes of
          text in every prompt can be expensive (as the API costs are usually calculated on the number of input and
          output tokens), especially in multi-turn dialogues. Moreover, too long context can “crowd out” the space
          needed for the user's query, the conversation history, and the model's generated output, potentially leading
          to truncated or less coherent responses. We will discuss how to handle the long context window in Section  <a href="advanced-context.html"><em>Managing Long Context</em></a>.
        </p>
      </section>

      <section id="retrieval-augmented-generation" class="content-section">
        <h2 class="section-title">Retrieval-Augmented Generation</h2>
        <p>
          When dealing with a large corpus of documents, RAG offers a more scalable and efficient solution. Instead of attempting to fit all possible information into the context window, RAG operates on a “just-in-time” basis by retrieving only the most relevant snippets of knowledge in response to the user's query. Taking the medical scenario as an example, this allows an agent to pull specific symptom descriptions for cardiac ischemia from a vast medical database to provide precise, expert-level advice. Standard RAG often treats knowledge chunks as independent, parallel pieces of information, but the user can also explore different ways to construct the knowledge base according to their needs. For example, by incorporating a knowledge graph, the system can represent the intricate relationships between different concepts and entities, and thus fetches not just directly relevant text but also interconnected information. Finally, RAG is not limited to a static set of documents. The retrieval mechanism can be extended to pull information from a wide variety of sources, including structured databases (e.g., via text-to-SQL queries) or live web searches, ensuring the agent has access to the most current information available.
        </p>
      </section>

      <section id="fine-tuning" class="content-section">
        <h2 class="section-title">Fine-Tuning</h2>
        <p>
          A third approach is to embed domain knowledge directly into the LLM's parameter weights through fine-tuning. This process involves further training the pre-trained model on a custom dataset specific to the target domain. Full-Parameter Fine-Tuning would modify all of the model's weights, which offers the highest potential for performance but is extremely resource-intensive. In contrast, methods as LoRA (Low-Rank Adaptation) or adapters freeze most of the model's parameters and only train a small set of new ones, known as Parameter-Efficient Fine-Tuning (PEFT). This dramatically reduces computational costs and makes fine-tuning more accessible. Fine-tuning does more than just teach the model facts; it changes its behavior and makes the knowledge an intrinsic part of its reasoning process. Meanwhile, since the knowledge is stored in the model's weights, the user does not need to include large amounts of text in the prompt during inference. This leads to faster response times and lower operational costs, which is especially beneficial for high-volume applications.
        </p>
      </section>

      <p class="citation-intro">If you find this work helpful, please consider citing our paper:</p>
      <section class="citation-block">
        <pre><code>@article{hu2025llm_agents_tutorial,
  title={A Beginner-Friendly Tutorial on LLM-based Agents},
  author={Hu, Shuyue and Ren, Siyue and Chen, Yang and Mu, Chunjiang and Liu, Jinyi and Cui, Zhiyao and Zhang, Yiqun and Li, Hao and Zhou, Dongzhan and Xu, Jia and Zhang, Qiaosheng and Han, Chu and Zheng, Yan and Hao, Jianye and Wang, Zhen},
  year={2025},
  month={November},
  note={Manuscript in preparation}
}</code></pre>
      </section>
      <div class="page-nav">
        <a class="page-nav-btn" href="index.html">Back to Home</a>
        <a class="page-nav-btn primary" href="advanced-reasoning.html">Next</a>
      </div>
    </main>
    <aside class="progress-sidebar">
      <h2>On this page</h2>
      <ul class="progress-list">
        <li><a class="progress-link" data-target="topic-overview" href="#topic-overview">Overview</a></li>
        <li><a class="progress-link" data-target="in-context-learning" href="#in-context-learning">In-context
            learning</a></li>
      </ul>
      <div class="progress-meter">
        <div class="progress-meter-fill"></div>
      </div>
    </aside>
  </div>

  <footer class="footer">© 2025 Hu et al. · Advanced techniques summary.</footer>
</body>

</html>